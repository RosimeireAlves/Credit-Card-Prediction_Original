{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\python.exe\n",
      "3.7.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy==1.16.4 for tensorflow 1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "1.18.1\n",
      "0.23.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\kx764qe\\Desktop\\general\\EY Badages\\Machine-learning-practical-6-real-applications\\module-credit-fraud\\Dataset'\n",
    "\n",
    "os.chdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run below to understand the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# data['NormalizedAmount'] = scaler.fit_transform(data['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data['NormalizedAmount'] = scaler.fit_transform(data['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>NormalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V22       V23       V24       V25       V26  \\\n",
       "0  0.098698  0.363787  ...  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
       "1  0.085102 -0.255425  ... -0.638672  0.101288 -0.339846  0.167170  0.125895   \n",
       "2  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
       "3  0.377436 -1.387024  ...  0.005274 -0.190321 -1.175575  0.647376 -0.221929   \n",
       "4 -0.270533  0.817739  ...  0.798278 -0.137458  0.141267 -0.206010  0.502292   \n",
       "\n",
       "        V27       V28  Amount  Class  NormalizedAmount  \n",
       "0  0.133558 -0.021053  149.62      0          0.244964  \n",
       "1 -0.008983  0.014724    2.69      0         -0.342475  \n",
       "2 -0.055353 -0.059752  378.66      0          1.160686  \n",
       "3  0.062723  0.061458  123.50      0          0.140534  \n",
       "4  0.219422  0.215153   69.99      0         -0.073403  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Amount', 'Time'], axis = 1)\n",
    "y = data['Class']\n",
    "X = data.drop(['Class'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>NormalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  NormalizedAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053          0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724         -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752          1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458          0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153         -0.073403  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>NormalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161145</th>\n",
       "      <td>-0.132066</td>\n",
       "      <td>0.107044</td>\n",
       "      <td>-0.650588</td>\n",
       "      <td>-0.996032</td>\n",
       "      <td>1.814333</td>\n",
       "      <td>1.740740</td>\n",
       "      <td>0.496852</td>\n",
       "      <td>0.633016</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>-0.362707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062612</td>\n",
       "      <td>-0.062489</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.251519</td>\n",
       "      <td>-2.466810</td>\n",
       "      <td>-0.889690</td>\n",
       "      <td>0.337462</td>\n",
       "      <td>0.306395</td>\n",
       "      <td>0.074817</td>\n",
       "      <td>-0.161761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204520</th>\n",
       "      <td>2.125994</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>-1.514760</td>\n",
       "      <td>0.115021</td>\n",
       "      <td>0.598510</td>\n",
       "      <td>-0.333235</td>\n",
       "      <td>0.199289</td>\n",
       "      <td>-0.264353</td>\n",
       "      <td>0.384111</td>\n",
       "      <td>0.028747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086076</td>\n",
       "      <td>-0.329368</td>\n",
       "      <td>-0.788150</td>\n",
       "      <td>0.267730</td>\n",
       "      <td>0.066122</td>\n",
       "      <td>-0.135785</td>\n",
       "      <td>0.203841</td>\n",
       "      <td>-0.068267</td>\n",
       "      <td>-0.057678</td>\n",
       "      <td>-0.345313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182659</th>\n",
       "      <td>-0.086694</td>\n",
       "      <td>0.166240</td>\n",
       "      <td>1.573127</td>\n",
       "      <td>0.687266</td>\n",
       "      <td>0.222359</td>\n",
       "      <td>1.102606</td>\n",
       "      <td>1.575093</td>\n",
       "      <td>-1.098608</td>\n",
       "      <td>0.763887</td>\n",
       "      <td>1.404677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052960</td>\n",
       "      <td>0.015324</td>\n",
       "      <td>1.063663</td>\n",
       "      <td>-0.410841</td>\n",
       "      <td>0.722723</td>\n",
       "      <td>-0.171733</td>\n",
       "      <td>-0.613543</td>\n",
       "      <td>-1.201571</td>\n",
       "      <td>-1.139931</td>\n",
       "      <td>0.326845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25117</th>\n",
       "      <td>1.352339</td>\n",
       "      <td>-0.534984</td>\n",
       "      <td>0.555143</td>\n",
       "      <td>-0.629355</td>\n",
       "      <td>-1.144170</td>\n",
       "      <td>-0.852967</td>\n",
       "      <td>-0.642128</td>\n",
       "      <td>-0.032659</td>\n",
       "      <td>-0.654482</td>\n",
       "      <td>0.619206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066712</td>\n",
       "      <td>-0.014814</td>\n",
       "      <td>-0.180379</td>\n",
       "      <td>0.178112</td>\n",
       "      <td>0.347720</td>\n",
       "      <td>0.151810</td>\n",
       "      <td>-0.404361</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>0.016152</td>\n",
       "      <td>-0.329401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227642</th>\n",
       "      <td>-1.526760</td>\n",
       "      <td>0.647782</td>\n",
       "      <td>0.615391</td>\n",
       "      <td>-0.561114</td>\n",
       "      <td>0.836950</td>\n",
       "      <td>-0.514251</td>\n",
       "      <td>0.984325</td>\n",
       "      <td>-0.097430</td>\n",
       "      <td>-0.062634</td>\n",
       "      <td>-1.033567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073333</td>\n",
       "      <td>-0.221533</td>\n",
       "      <td>-0.393158</td>\n",
       "      <td>-0.214990</td>\n",
       "      <td>0.588447</td>\n",
       "      <td>0.679496</td>\n",
       "      <td>0.518434</td>\n",
       "      <td>0.065022</td>\n",
       "      <td>0.147294</td>\n",
       "      <td>0.006398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "161145 -0.132066  0.107044 -0.650588 -0.996032  1.814333  1.740740  0.496852   \n",
       "204520  2.125994  0.014207 -1.514760  0.115021  0.598510 -0.333235  0.199289   \n",
       "182659 -0.086694  0.166240  1.573127  0.687266  0.222359  1.102606  1.575093   \n",
       "25117   1.352339 -0.534984  0.555143 -0.629355 -1.144170 -0.852967 -0.642128   \n",
       "227642 -1.526760  0.647782  0.615391 -0.561114  0.836950 -0.514251  0.984325   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "161145  0.633016  0.017181 -0.362707  ... -0.062612 -0.062489  0.005292   \n",
       "204520 -0.264353  0.384111  0.028747  ... -0.086076 -0.329368 -0.788150   \n",
       "182659 -1.098608  0.763887  1.404677  ...  0.052960  0.015324  1.063663   \n",
       "25117  -0.032659 -0.654482  0.619206  ... -0.066712 -0.014814 -0.180379   \n",
       "227642 -0.097430 -0.062634 -1.033567  ... -0.073333 -0.221533 -0.393158   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  \\\n",
       "161145  0.251519 -2.466810 -0.889690  0.337462  0.306395  0.074817   \n",
       "204520  0.267730  0.066122 -0.135785  0.203841 -0.068267 -0.057678   \n",
       "182659 -0.410841  0.722723 -0.171733 -0.613543 -1.201571 -1.139931   \n",
       "25117   0.178112  0.347720  0.151810 -0.404361  0.013746  0.016152   \n",
       "227642 -0.214990  0.588447  0.679496  0.518434  0.065022  0.147294   \n",
       "\n",
       "        NormalizedAmount  \n",
       "161145         -0.161761  \n",
       "204520         -0.345313  \n",
       "182659          0.326845  \n",
       "25117          -0.329401  \n",
       "227642          0.006398  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert data to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identity = X_train.index\n",
    "test_identity = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#add input layer\n",
    "model.add(Dense(input_dim = 29, units = 16, activation = 'relu'))\n",
    "#add 2nd hidden layer\n",
    "model.add(Dense(units = 24, activation = 'relu'))\n",
    "#add dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "#add 3rd hidden layer\n",
    "model.add(Dense(units = 20, activation = 'relu'))\n",
    "#add 4th hidden layer\n",
    "model.add(Dense(units = 24, activation = 'relu'))\n",
    "#add ouptut layer\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Dense(input_dim = 29, units = 16, activation = 'relu'), \n",
    "#     Dense(units = 24, activation = 'relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(units = 20, activation = 'relu'),\n",
    "#     Dense(units = 24, activation = 'relu'),\n",
    "#     Dense(units =1, activation = 'sigmoid'),    \n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                504       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,917\n",
      "Trainable params: 1,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kx764qe\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kx764qe\\AppData\\Local\\Continuum\\anaconda3\\envs\\courses\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "199364/199364 [==============================] - 31s 157us/step - loss: 0.0099 - acc: 0.9979\n",
      "Epoch 2/5\n",
      "199364/199364 [==============================] - 29s 144us/step - loss: 0.0039 - acc: 0.9993\n",
      "Epoch 3/5\n",
      "199364/199364 [==============================] - 23s 115us/step - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 4/5\n",
      "199364/199364 [==============================] - 24s 119us/step - loss: 0.0034 - acc: 0.9994\n",
      "Epoch 5/5\n",
      "199364/199364 [==============================] - 24s 120us/step - loss: 0.0034 - acc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1801dbb2eb8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = 15, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85443/85443 [==============================] - 2s 20us/step\n",
      "[0.004324613565862002, 0.999403110845827]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion Matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85276    20]\n",
      " [   31   116]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred.round())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, classes = [0,1], title='Confusion Matrix - Test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999403110845827\n",
      "0.8529411764705882\n",
      "0.7891156462585034\n",
      "0.8197879858657242\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred.round()))\n",
    "print(precision_score(y_test, y_pred.round()))\n",
    "print(recall_score(y_test, y_pred.round()))\n",
    "print(f1_score(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
